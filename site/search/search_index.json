{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home The Haig Fras Digital Twin project aims to establish a system representing a Digital Twin for the Haig Fras environmental protection area in the Celtic Sea. General Project Infrastructure This project is based on a web-client that accesses data from different locations and uses various microservices related to APIs and tile servers. Below, we will describe the project's infrastructure in more detail. As shown in the figure above, both the frontend and all microservices are running in Docker containers. These Docker containers are stored in a container registry. Currently, we are using the container registry of BODC, based on Nexus, and the Oracle Cloud. The containers are updated each time a push is made to the master repository of the container. The final versions of the docker containers are available below: Frontend: docker-repo.bodc.me/oceaninfo/imfe-pilot/frontend:v1.0 API: docker-repo.bodc.me/oceaninfo/imfe-pilot/api_calculations_use_cases_web:v1.0 Tileserver: docker-repo.bodc.me/oceaninfo/imfe-pilot/tileserver:v1.0 MBTiles Server: docker-repo.bodc.me/oceaninfo/imfe-pilot/mbtiles:v1.0 Docker monitor: docker-repo.bodc.me/oceaninfo/imfe-pilot/monitor_docker:v1.0 Prototype Before the start of the project, a prototype of the system was developed to understand the user journey throughout the application usage. This prototype was developed using FIGMA, which was essential for understanding many of the features that would later be integrated and for facilitating the platform's styling programming. The final version of the FIGMA prototype can be accessed here . Repositories These are the project repositories: bodc-code : This was the initial repository of the project when it was conceived. It contains the early drafts of the code used in the project. Additionally, it still holds a significant portion of the documentation related to data format conversion. Data Pipelines : This repository contains all the code for data format conversion, data uploading to the Object Store, and STAC Catalog creation. frontend : A frontend application created in React, with the ability to interact with different data formats on both the backend and frontend. This project depends on certain backend services to perform tile server activities, as well as authentication and data calculations. tileserver : Repository for configuring and creating tile servers. monitor_docker : A Python package for monitoring container operation on the server. frontend_test : Repository containing Selenium tests for the frontend. salt_config : Repository contaning the Salt configuration for the VM. Server Instance Organization The organization of server instances is carried out through the salt_config repository. This repository is based on the configuration of server stacks in the Salt project . More information about the use and configuration of Salt can be found in the Salt repository in this project . Deploying the Project To deploy the project, follow the procedures described here . CI/CD Pipeline This repository includes an automatic GitLab CI/CD pipeline for continuous integration and continuous deployment. More information about this pipeline can be found in the CI/CD Pipeline documentation . Data Organization: Object Store and STAC Catalog All project data files are stored in an object store. In this case, the files are accessed via HTTP requests, without the need for an intermediate database or an API. As the object store appears as a group of files, it is necessary to create a catalog of these files, called an STAC Catalog . The STAC catalog for this project can be accessed here . For more information on how to generate the STAC Catalog, refer to the Data Pipelines repository . This project suggests an organization of files in the Object Store, as described here . If you want to understand a little bit more about how we deal with STAC Catalogs, please click here . Data Format Conversion In this project, data from different formats is converted into formats optimized for the cloud. Data conversion is performed through a series of Python codes that convert data from the following formats: GeoTIFF, GeoJSON, Shapefile, FlatGeoBuf, COG, Zarr, NetCDF, among others. The codes for converting data are described in the Data Pipelines repository . More information about all the data types that we have been working with are described below: - Cloud Optimized GeoTIFF - MBTiles - WMS Layers - Cesium Ion - CSV - Organisms Annotation Authentication To control access to the project's frontend, two types of authentication have been implemented: ORCID and Microsoft 365. More information can be found here . Frontend Application The frontend application was developed in React and is converted into a Docker container. This app is currently running on Jasmin and Oracle Cloud and can be accessed via the links https://imfe-pilot.noc.ac.uk and https://haigfras-salt.co.uk . You can find a detailed explanation about all the frontend features here . More information about the frontend application can be found in the repository: https://github.com/NOC-OI/imfe-pilot-frontend Backend Application Although the frontend application does not necessarily require a backend to perform most of its activities, a backend was still implemented in the project. The backend is used for the following activities: Server-side calculations for the Digital Twin for Haig Fras project. Management and access to the user table, enabling authentication. This app is currently running on Jasmin and Oracle Cloud and can be accessed via the links https://imfe-pilot-api.noc.ac.uk and https://haigfras-salt-api.co.uk . More information about the backend application can be found in the repository or in this link . Tile Servers Some data formats require the use of tile servers to optimize data rendering on the frontend. For this project, the following servers are used: 1) Titiler: FastAPI application for dynamic tiling. It is used for COG files. You can see more information here . 2) MBTiles: a Python server for organizing mbtiles files from object stores. You can see more information here . The tile servers are converted into Docker containers. More information about the servers can be found in the repository: https://github.com/NOC-OI/imfe-pilot-frontend_tests . Application Tests A repository was created with the aim of conducting integration tests for the project. With these tests, it is possible to assess whether any changes to the frontend or any of the microservices will or will not impact the project as a whole. Further information can be found in the project repository: https://github.com/NOC-OI/imfe-pilot-frontend_tests . Container Monitoring To monitor the availability of the frontend application, as well as the microservices, a package has been implemented with the objective to monitor the operation of Docker containers on a virtual machine (VM). This package operates as follows: At certain time intervals, the VM will run a script that saves a CSV file with the status of all containers (including those already finished). A set of commands within a Docker container, also on the VM, will evaluate this file. If there are any changes in the status of the containers or if they are not functioning properly, an email group will be notified. If any container encounters an issue, an email will be sent with the subject \"Issues with container(s): {container-names}\". If the situation returns to normal, an email with the subject \"Containers OK!\" will be sent, indicating that all containers are now working correctly. More information about this task can be found in the repository: https://github.com/NOC-OI/monitor_docker .","title":"Home"},{"location":"#home","text":"The Haig Fras Digital Twin project aims to establish a system representing a Digital Twin for the Haig Fras environmental protection area in the Celtic Sea.","title":"Home"},{"location":"#general-project-infrastructure","text":"This project is based on a web-client that accesses data from different locations and uses various microservices related to APIs and tile servers. Below, we will describe the project's infrastructure in more detail. As shown in the figure above, both the frontend and all microservices are running in Docker containers. These Docker containers are stored in a container registry. Currently, we are using the container registry of BODC, based on Nexus, and the Oracle Cloud. The containers are updated each time a push is made to the master repository of the container. The final versions of the docker containers are available below: Frontend: docker-repo.bodc.me/oceaninfo/imfe-pilot/frontend:v1.0 API: docker-repo.bodc.me/oceaninfo/imfe-pilot/api_calculations_use_cases_web:v1.0 Tileserver: docker-repo.bodc.me/oceaninfo/imfe-pilot/tileserver:v1.0 MBTiles Server: docker-repo.bodc.me/oceaninfo/imfe-pilot/mbtiles:v1.0 Docker monitor: docker-repo.bodc.me/oceaninfo/imfe-pilot/monitor_docker:v1.0","title":"General Project Infrastructure"},{"location":"#prototype","text":"Before the start of the project, a prototype of the system was developed to understand the user journey throughout the application usage. This prototype was developed using FIGMA, which was essential for understanding many of the features that would later be integrated and for facilitating the platform's styling programming. The final version of the FIGMA prototype can be accessed here .","title":"Prototype"},{"location":"#repositories","text":"These are the project repositories: bodc-code : This was the initial repository of the project when it was conceived. It contains the early drafts of the code used in the project. Additionally, it still holds a significant portion of the documentation related to data format conversion. Data Pipelines : This repository contains all the code for data format conversion, data uploading to the Object Store, and STAC Catalog creation. frontend : A frontend application created in React, with the ability to interact with different data formats on both the backend and frontend. This project depends on certain backend services to perform tile server activities, as well as authentication and data calculations. tileserver : Repository for configuring and creating tile servers. monitor_docker : A Python package for monitoring container operation on the server. frontend_test : Repository containing Selenium tests for the frontend. salt_config : Repository contaning the Salt configuration for the VM.","title":"Repositories"},{"location":"#server-instance-organization","text":"The organization of server instances is carried out through the salt_config repository. This repository is based on the configuration of server stacks in the Salt project . More information about the use and configuration of Salt can be found in the Salt repository in this project .","title":"Server Instance Organization"},{"location":"#deploying-the-project","text":"To deploy the project, follow the procedures described here .","title":"Deploying the Project"},{"location":"#cicd-pipeline","text":"This repository includes an automatic GitLab CI/CD pipeline for continuous integration and continuous deployment. More information about this pipeline can be found in the CI/CD Pipeline documentation .","title":"CI/CD Pipeline"},{"location":"#data-organization-object-store-and-stac-catalog","text":"All project data files are stored in an object store. In this case, the files are accessed via HTTP requests, without the need for an intermediate database or an API. As the object store appears as a group of files, it is necessary to create a catalog of these files, called an STAC Catalog . The STAC catalog for this project can be accessed here . For more information on how to generate the STAC Catalog, refer to the Data Pipelines repository . This project suggests an organization of files in the Object Store, as described here . If you want to understand a little bit more about how we deal with STAC Catalogs, please click here .","title":"Data Organization: Object Store and STAC Catalog"},{"location":"#data-format-conversion","text":"In this project, data from different formats is converted into formats optimized for the cloud. Data conversion is performed through a series of Python codes that convert data from the following formats: GeoTIFF, GeoJSON, Shapefile, FlatGeoBuf, COG, Zarr, NetCDF, among others. The codes for converting data are described in the Data Pipelines repository . More information about all the data types that we have been working with are described below: - Cloud Optimized GeoTIFF - MBTiles - WMS Layers - Cesium Ion - CSV - Organisms Annotation","title":"Data Format Conversion"},{"location":"#authentication","text":"To control access to the project's frontend, two types of authentication have been implemented: ORCID and Microsoft 365. More information can be found here .","title":"Authentication"},{"location":"#frontend-application","text":"The frontend application was developed in React and is converted into a Docker container. This app is currently running on Jasmin and Oracle Cloud and can be accessed via the links https://imfe-pilot.noc.ac.uk and https://haigfras-salt.co.uk . You can find a detailed explanation about all the frontend features here . More information about the frontend application can be found in the repository: https://github.com/NOC-OI/imfe-pilot-frontend","title":"Frontend Application"},{"location":"#backend-application","text":"Although the frontend application does not necessarily require a backend to perform most of its activities, a backend was still implemented in the project. The backend is used for the following activities: Server-side calculations for the Digital Twin for Haig Fras project. Management and access to the user table, enabling authentication. This app is currently running on Jasmin and Oracle Cloud and can be accessed via the links https://imfe-pilot-api.noc.ac.uk and https://haigfras-salt-api.co.uk . More information about the backend application can be found in the repository or in this link .","title":"Backend Application"},{"location":"#tile-servers","text":"Some data formats require the use of tile servers to optimize data rendering on the frontend. For this project, the following servers are used: 1) Titiler: FastAPI application for dynamic tiling. It is used for COG files. You can see more information here . 2) MBTiles: a Python server for organizing mbtiles files from object stores. You can see more information here . The tile servers are converted into Docker containers. More information about the servers can be found in the repository: https://github.com/NOC-OI/imfe-pilot-frontend_tests .","title":"Tile Servers"},{"location":"#application-tests","text":"A repository was created with the aim of conducting integration tests for the project. With these tests, it is possible to assess whether any changes to the frontend or any of the microservices will or will not impact the project as a whole. Further information can be found in the project repository: https://github.com/NOC-OI/imfe-pilot-frontend_tests .","title":"Application Tests"},{"location":"#container-monitoring","text":"To monitor the availability of the frontend application, as well as the microservices, a package has been implemented with the objective to monitor the operation of Docker containers on a virtual machine (VM). This package operates as follows: At certain time intervals, the VM will run a script that saves a CSV file with the status of all containers (including those already finished). A set of commands within a Docker container, also on the VM, will evaluate this file. If there are any changes in the status of the containers or if they are not functioning properly, an email group will be notified. If any container encounters an issue, an email will be sent with the subject \"Issues with container(s): {container-names}\". If the situation returns to normal, an email with the subject \"Containers OK!\" will be sent, indicating that all containers are now working correctly. More information about this task can be found in the repository: https://github.com/NOC-OI/monitor_docker .","title":"Container Monitoring"},{"location":"2dmap/","text":"2D Map Introduction Our 2D map version is built upon the React Leaflet library, offering a feature-rich platform for visualizing geospatial data. In this documentation, we'll delve into the details of our 2D map implementation, the base map layers used, and how interaction with the map is facilitated. The Foundation: React Leaflet To create our 2D map, we've harnessed the power of the React Leaflet library. React Leaflet provides a robust framework for building interactive and visually engaging maps within a React application. To enhance our map's capabilities and interactivity, we've developed additional packages, which will be detailed in the following sections. Base Map Layers A map's foundation lies in its base layers, and for our 2D map, we have incorporated the following base layers: OpenStreetMap : This layer is sourced from OpenStreetMap and is accessible via the following URL: OpenStreetMap Layer . NASA Blue Marble : This layer is derived from NASA's Blue Marble imagery and can be accessed through the URL: NASA Blue Marble Layer . These base layers provide essential geographical context for our 2D map, serving as a canvas on which various geospatial data can be visualized. Above is a visual representation of our 2D map, showcasing its usage with React Leaflet. Map Interaction Interacting with the map is a fundamental aspect of geospatial applications. In our implementation, interaction with the map is facilitated through the definition of a 'ref' prop within the MapContainer component from React Leaflet. This 'ref' prop is passed a setState function called setMap, created within the Map component. When a layer is added to the map, it is assigned a unique 'attribution' value. This attribution value is crucial for identifying and interacting with specific layers on the map. We utilize this value to perform the necessary operations when interacting with the layer. It's worth mentioning that due to certain restrictions in Webpack for use with React Vite, we faced limitations in adding multiple Leaflet auxiliary libraries to the project. To overcome this challenge, these libraries were manually included in the project by copying the associated .js files to the repository. The following libraries have been integrated: leaflet-ruler.js : This library allows users to measure distances on the map. vectorgrid : Enables the addition of MBTiles files to the map. CanvasLayers : Provides support for adding .asc files to the map. This combination of React Leaflet, base map layers, and supplementary libraries ensures a feature-rich and interactive 2D map for our geospatial applications. If you have any questions or require further information about our 2D map implementation, please consult the project repository or reach out to our support team for assistance.","title":"2D Map"},{"location":"2dmap/#2d-map","text":"","title":"2D Map"},{"location":"2dmap/#introduction","text":"Our 2D map version is built upon the React Leaflet library, offering a feature-rich platform for visualizing geospatial data. In this documentation, we'll delve into the details of our 2D map implementation, the base map layers used, and how interaction with the map is facilitated.","title":"Introduction"},{"location":"2dmap/#the-foundation-react-leaflet","text":"To create our 2D map, we've harnessed the power of the React Leaflet library. React Leaflet provides a robust framework for building interactive and visually engaging maps within a React application. To enhance our map's capabilities and interactivity, we've developed additional packages, which will be detailed in the following sections.","title":"The Foundation: React Leaflet"},{"location":"2dmap/#base-map-layers","text":"A map's foundation lies in its base layers, and for our 2D map, we have incorporated the following base layers: OpenStreetMap : This layer is sourced from OpenStreetMap and is accessible via the following URL: OpenStreetMap Layer . NASA Blue Marble : This layer is derived from NASA's Blue Marble imagery and can be accessed through the URL: NASA Blue Marble Layer . These base layers provide essential geographical context for our 2D map, serving as a canvas on which various geospatial data can be visualized. Above is a visual representation of our 2D map, showcasing its usage with React Leaflet.","title":"Base Map Layers"},{"location":"2dmap/#map-interaction","text":"Interacting with the map is a fundamental aspect of geospatial applications. In our implementation, interaction with the map is facilitated through the definition of a 'ref' prop within the MapContainer component from React Leaflet. This 'ref' prop is passed a setState function called setMap, created within the Map component. When a layer is added to the map, it is assigned a unique 'attribution' value. This attribution value is crucial for identifying and interacting with specific layers on the map. We utilize this value to perform the necessary operations when interacting with the layer. It's worth mentioning that due to certain restrictions in Webpack for use with React Vite, we faced limitations in adding multiple Leaflet auxiliary libraries to the project. To overcome this challenge, these libraries were manually included in the project by copying the associated .js files to the repository. The following libraries have been integrated: leaflet-ruler.js : This library allows users to measure distances on the map. vectorgrid : Enables the addition of MBTiles files to the map. CanvasLayers : Provides support for adding .asc files to the map. This combination of React Leaflet, base map layers, and supplementary libraries ensures a feature-rich and interactive 2D map for our geospatial applications. If you have any questions or require further information about our 2D map implementation, please consult the project repository or reach out to our support team for assistance.","title":"Map Interaction"},{"location":"3dmap/","text":"3D Map Introduction Our 3D map version is built upon the Resium library, which is essentially Cesium for React. This powerful library serves as the foundation for creating interactive and immersive 3D geospatial experiences within our application. In this documentation, we'll explore the details of our 3D map implementation, interactions with the map, and essential observations for development and production use. The image above provides an overview of our 3D map utilizing Resium. Map Interaction Interacting with the 3D map is a critical aspect of our geospatial application. To enable map interaction, we define a 'ref' prop within the Resium Viewer component. This 'ref' prop is passed a useRef created within the 3D Map component. This approach provides a means for managing and interacting with the 3D map. Similar to the 2D map, layers added to the 3D map are assigned a unique 'attribution' value. This value is vital for identifying and interacting with specific layers on the map. When an operation or interaction with a layer is required, the map seeks the layer with the corresponding attribution value, allowing for seamless interaction. It's essential to note that the Cesium library handles layers differently from Leaflet. In Cesium, each type of layer is treated as a separate component. Furthermore, some layers in Cesium are not easily modifiable. This has led to the decision to remove and re-add layers in many cases to ensure they function as intended. Important Observations While developing with React, it's important to be aware of a characteristic where React renders all components on the page twice. This behavior is a valuable feature for development testing but can present challenges when working with Resium. In practice, React renders two 3D maps, with only the second map being interactive. To address this and ensure that you can effectively test and use the map during development, follow these steps: Remove the 'full' prop from the Viewer component. Add the following information to the 'styles.ts' file of the 3D map component: export const ResiumContainer = styled.div` /* div:first-child { div:first-child { height: 500px; } } */ ` These adjustments should be removed when deploying the application for production use. Additional Note It's worth mentioning that we have also implemented an example map using MapBox3D. However, it is not currently in production and serves as a separate experimental component. Our 3D map implementation opens up new possibilities for immersive geospatial experiences, and we are committed to continually enhancing its functionality. If you have any questions or need further information regarding our 3D map implementation, please consult the project repository or reach out to our support team for assistance.","title":"3D Map"},{"location":"3dmap/#3d-map","text":"","title":"3D Map"},{"location":"3dmap/#introduction","text":"Our 3D map version is built upon the Resium library, which is essentially Cesium for React. This powerful library serves as the foundation for creating interactive and immersive 3D geospatial experiences within our application. In this documentation, we'll explore the details of our 3D map implementation, interactions with the map, and essential observations for development and production use. The image above provides an overview of our 3D map utilizing Resium.","title":"Introduction"},{"location":"3dmap/#map-interaction","text":"Interacting with the 3D map is a critical aspect of our geospatial application. To enable map interaction, we define a 'ref' prop within the Resium Viewer component. This 'ref' prop is passed a useRef created within the 3D Map component. This approach provides a means for managing and interacting with the 3D map. Similar to the 2D map, layers added to the 3D map are assigned a unique 'attribution' value. This value is vital for identifying and interacting with specific layers on the map. When an operation or interaction with a layer is required, the map seeks the layer with the corresponding attribution value, allowing for seamless interaction. It's essential to note that the Cesium library handles layers differently from Leaflet. In Cesium, each type of layer is treated as a separate component. Furthermore, some layers in Cesium are not easily modifiable. This has led to the decision to remove and re-add layers in many cases to ensure they function as intended.","title":"Map Interaction"},{"location":"3dmap/#important-observations","text":"While developing with React, it's important to be aware of a characteristic where React renders all components on the page twice. This behavior is a valuable feature for development testing but can present challenges when working with Resium. In practice, React renders two 3D maps, with only the second map being interactive. To address this and ensure that you can effectively test and use the map during development, follow these steps: Remove the 'full' prop from the Viewer component. Add the following information to the 'styles.ts' file of the 3D map component: export const ResiumContainer = styled.div` /* div:first-child { div:first-child { height: 500px; } } */ ` These adjustments should be removed when deploying the application for production use.","title":"Important Observations"},{"location":"3dmap/#additional-note","text":"It's worth mentioning that we have also implemented an example map using MapBox3D. However, it is not currently in production and serves as a separate experimental component. Our 3D map implementation opens up new possibilities for immersive geospatial experiences, and we are committed to continually enhancing its functionality. If you have any questions or need further information regarding our 3D map implementation, please consult the project repository or reach out to our support team for assistance.","title":"Additional Note"},{"location":"about/","text":"About The Haig Fras Digital Twin project aims to establish a system representing a Digital Twin for the Haig Fras environmental protection area in the Celtic Sea. Definition An environmental digital twin is a virtual representation or model of a physical environment. This digital twin is created using various data sources, including sensor data, satellite imagery, geospatial information, and other relevant data sources. Key characteristics and functionalities of an environmental digital twin include: Real-time Data Integration: Environmental digital twins often incorporate real-time data streams. Visualization: They enable the visualization of the environment in a digital format, allowing users to explore and interact with the data, often through 3D models or interactive maps. Data Analysis: They often include data analytics tools to process and analyze the vast amount of data associated with the environment, helping identify patterns, trends, and anomalies. Decision Support: Environmental digital twins serve as decision support tools for a range of applications, including resource conservation and environmental protection. Interoperability: They are designed to work within larger systems and can often be integrated with other digital twins or databases to provide a more comprehensive understanding of complex interactions and relationships in the environment. Environmental digital twins are valuable tools for understanding and managing various aspects of our environment, helping us address challenges related to climate change, sustainable development, natural resource management, and more. They play a crucial role in enabling data-driven, evidence-based decision-making in these areas.","title":"About"},{"location":"about/#about","text":"The Haig Fras Digital Twin project aims to establish a system representing a Digital Twin for the Haig Fras environmental protection area in the Celtic Sea.","title":"About"},{"location":"about/#definition","text":"An environmental digital twin is a virtual representation or model of a physical environment. This digital twin is created using various data sources, including sensor data, satellite imagery, geospatial information, and other relevant data sources. Key characteristics and functionalities of an environmental digital twin include: Real-time Data Integration: Environmental digital twins often incorporate real-time data streams. Visualization: They enable the visualization of the environment in a digital format, allowing users to explore and interact with the data, often through 3D models or interactive maps. Data Analysis: They often include data analytics tools to process and analyze the vast amount of data associated with the environment, helping identify patterns, trends, and anomalies. Decision Support: Environmental digital twins serve as decision support tools for a range of applications, including resource conservation and environmental protection. Interoperability: They are designed to work within larger systems and can often be integrated with other digital twins or databases to provide a more comprehensive understanding of complex interactions and relationships in the environment. Environmental digital twins are valuable tools for understanding and managing various aspects of our environment, helping us address challenges related to climate change, sustainable development, natural resource management, and more. They play a crucial role in enabling data-driven, evidence-based decision-making in these areas.","title":"Definition"},{"location":"authentication/","text":"Authentication Our application supports two methods of authentication: using ORCID and Microsoft 365. In both cases, the application functions as follows: Creating Applications on the Platforms To use these authentication methods, you need to register your application with the respective platforms. ORCID Log in to your ORCID account and visit the following link: ORCID Developer Tools . Follow the steps outlined in this guide: Registering a Public API Client . After registering your application, you should update the following information in the .env file of the frontend project: VITE_ORCID_CLIENT_ID= VITE_ORCID_CLIENT_SECRET= These details should also be updated in the backend application: VITE_ORCID_CLIENT_ID= VITE_ORCID_CLIENT_SECRET= VITE_ORCID_CLIENT_REDIRECT_URI= Microsoft 365 For Microsoft 365, start by creating an account on Azure Cloud through this link: Azure Portal . If you create the account using your professional email, you will need to contact the Help Desk to request authorization for application creation. Once your account is created, register your application here: Azure App Registrations . Click \"New registration\" and provide the necessary information about your application. Next, click on \"API Permissions\" and add a new permission, as illustrated in the image below: Afterward, navigate to \"Certificates and Secrets\" and generate a new secret. Update the .env file as follows: VITE_365_CLIENT_ID= VITE_365_TENANCY_ID= VITE_365_REDIRECT_URI= These details should also be updated in the backend application. Authentication Process The application's authentication process follows these steps: Upon loading, the application checks for the presence of a 'token' cookie. This cookie contains a JWT (JSON Web Token) with user information. The token is sent to the backend, which converts it into a JSON format and verifies if the user exists and has the necessary authorization to access the application. This check is performed using a list of registered emails and ORCID IDs available in the backend. If the user is found and authorized, this information is sent to the frontend, granting access to the system. The 'src/lib/auth.ts' file handles this verification. If the user doesn't exist or if there is no 'token' cookie, users are directed to the login page: The login system connects with the applications created in ORCID and Microsoft 365 to obtain a single-use 'code'. This code provides access to the APIs of these applications and allows retrieval of user information. The single-use code is sent by the authenticators to the '/auth' route, which forwards it to the backend. Within the backend, communication with the ORCID and Microsoft 365 systems occurs to fetch user data. Finally, the backend returns a JWT token to the frontend, which is saved as a cookie. Note that the cookie has an expiration time set.","title":"Authentication"},{"location":"authentication/#authentication","text":"Our application supports two methods of authentication: using ORCID and Microsoft 365. In both cases, the application functions as follows:","title":"Authentication"},{"location":"authentication/#creating-applications-on-the-platforms","text":"To use these authentication methods, you need to register your application with the respective platforms.","title":"Creating Applications on the Platforms"},{"location":"authentication/#orcid","text":"Log in to your ORCID account and visit the following link: ORCID Developer Tools . Follow the steps outlined in this guide: Registering a Public API Client . After registering your application, you should update the following information in the .env file of the frontend project: VITE_ORCID_CLIENT_ID= VITE_ORCID_CLIENT_SECRET= These details should also be updated in the backend application: VITE_ORCID_CLIENT_ID= VITE_ORCID_CLIENT_SECRET= VITE_ORCID_CLIENT_REDIRECT_URI=","title":"ORCID"},{"location":"authentication/#microsoft-365","text":"For Microsoft 365, start by creating an account on Azure Cloud through this link: Azure Portal . If you create the account using your professional email, you will need to contact the Help Desk to request authorization for application creation. Once your account is created, register your application here: Azure App Registrations . Click \"New registration\" and provide the necessary information about your application. Next, click on \"API Permissions\" and add a new permission, as illustrated in the image below: Afterward, navigate to \"Certificates and Secrets\" and generate a new secret. Update the .env file as follows: VITE_365_CLIENT_ID= VITE_365_TENANCY_ID= VITE_365_REDIRECT_URI= These details should also be updated in the backend application.","title":"Microsoft 365"},{"location":"authentication/#authentication-process","text":"The application's authentication process follows these steps: Upon loading, the application checks for the presence of a 'token' cookie. This cookie contains a JWT (JSON Web Token) with user information. The token is sent to the backend, which converts it into a JSON format and verifies if the user exists and has the necessary authorization to access the application. This check is performed using a list of registered emails and ORCID IDs available in the backend. If the user is found and authorized, this information is sent to the frontend, granting access to the system. The 'src/lib/auth.ts' file handles this verification. If the user doesn't exist or if there is no 'token' cookie, users are directed to the login page: The login system connects with the applications created in ORCID and Microsoft 365 to obtain a single-use 'code'. This code provides access to the APIs of these applications and allows retrieval of user information. The single-use code is sent by the authenticators to the '/auth' route, which forwards it to the backend. Within the backend, communication with the ORCID and Microsoft 365 systems occurs to fetch user data. Finally, the backend returns a JWT token to the frontend, which is saved as a cookie. Note that the cookie has an expiration time set.","title":"Authentication Process"},{"location":"backend/","text":"Certainly! Here's the English translation of the provided text: API for User Authentication and Backend Calculations This API serves a dual purpose: It performs server-side calculations for the Digital Twin project focused on Haig Fras. It manages and provides access to the user table, enabling authentication. The API receives user data from the frontend, processes it, and returns data or calculation results. You can find more detailed information in the API repository . API Overview Detailed information about the API and its endpoints can be found in the \"api\" folder of the repository. This folder includes the \"fast.py\" file, which comprehensively describes all available endpoints and the corresponding functions they execute. Additionally, the v1 version of the calculations is documented in the \"api/v1\" folder. User Authentication The user authentication system relies on OAuth connections with ORCID and Microsoft 365 systems. To enable this functionality, the following steps have been taken: Register your application with ORCID and Microsoft. Configure the frontend application to facilitate login and obtain code information. Send this code to the backend to check if the user is among the authorized users (as listed in the \"orcid.json\" file). Connection with the backend is facilitated through endpoints (GET and POST requests). Create an \"orcid.json\" file, which should contain a list of ORCID IDs and Outlook email addresses that are permitted to access the frontend application. More information can be found here . Object Store Authentication Some files within the object store are not publicly accessible. In such cases, you can use this repository to obtain signed URLs for the object store files. These signed URLs must be encrypted using a token before passing them to the frontend. The same token must be used by any system responsible for decrypting the signed URLs. Calculations In this repository, we perform a list of calculations on the backend in order to obtain some statistics on the data or some biodiversity calculations. The following calculations are currently being performed in this project: - Calculation of mean, median, and standard deviation. - Calculation of density. - Calculation of biodiversity based on the Shannon index. - Calculation of biodiversity based on the Inverse Simpson Index.","title":"Backend"},{"location":"backend/#api-for-user-authentication-and-backend-calculations","text":"This API serves a dual purpose: It performs server-side calculations for the Digital Twin project focused on Haig Fras. It manages and provides access to the user table, enabling authentication. The API receives user data from the frontend, processes it, and returns data or calculation results. You can find more detailed information in the API repository .","title":"API for User Authentication and Backend Calculations"},{"location":"backend/#api-overview","text":"Detailed information about the API and its endpoints can be found in the \"api\" folder of the repository. This folder includes the \"fast.py\" file, which comprehensively describes all available endpoints and the corresponding functions they execute. Additionally, the v1 version of the calculations is documented in the \"api/v1\" folder.","title":"API Overview"},{"location":"backend/#user-authentication","text":"The user authentication system relies on OAuth connections with ORCID and Microsoft 365 systems. To enable this functionality, the following steps have been taken: Register your application with ORCID and Microsoft. Configure the frontend application to facilitate login and obtain code information. Send this code to the backend to check if the user is among the authorized users (as listed in the \"orcid.json\" file). Connection with the backend is facilitated through endpoints (GET and POST requests). Create an \"orcid.json\" file, which should contain a list of ORCID IDs and Outlook email addresses that are permitted to access the frontend application. More information can be found here .","title":"User Authentication"},{"location":"backend/#object-store-authentication","text":"Some files within the object store are not publicly accessible. In such cases, you can use this repository to obtain signed URLs for the object store files. These signed URLs must be encrypted using a token before passing them to the frontend. The same token must be used by any system responsible for decrypting the signed URLs.","title":"Object Store Authentication"},{"location":"backend/#calculations","text":"In this repository, we perform a list of calculations on the backend in order to obtain some statistics on the data or some biodiversity calculations. The following calculations are currently being performed in this project: - Calculation of mean, median, and standard deviation. - Calculation of density. - Calculation of biodiversity based on the Shannon index. - Calculation of biodiversity based on the Inverse Simpson Index.","title":"Calculations"},{"location":"cesium_ion/","text":"Cesium Ion 3D Layers This guide will take you through the process of opening Cesium Ion 3D layers in a React TypeScript (TSX) application using Resium. Cesium Ion is a cloud-based platform for creating, hosting, and streaming 3D geospatial content, while Resium is a library for integrating Cesium 3D globes with React. Configuring Cesium Ion Sign Up for Cesium Ion Before you can use Cesium Ion, you need to create an account on Cesium Ion . Once you have an account, you can obtain your access token. Set Your Access Token Add your Access Token value to the .env file: VITE_CESIUM_TOKEN= In the tsx file, set your Cesium Ion access token by including the following code in your application's entry point (e.g., index.tsx ): import { Ion } from 'cesium' Ion.defaultAccessToken = process.env.VITE_CESIUM_TOKEN Opening a Cesium Ion 3D Layer Import Required Modules Import the necessary modules: import React from 'react'; import { Viewer } from 'resium'; Define the Cesium Ion Layer Define the Cesium Ion layer within your component: const assetId = 'ASSET ID FROM THE CESIUM ION ACCOUNT' const terrainUrl = await Cesium.CesiumTerrainProvider.fromIonAssetId( assetId, ) ref.current.cesiumElement.terrainProvider = terrainUrl Please note that you will need to replace 'ASSET ID FROM THE CESIUM ION ACCOUNT' with the actual asset ID you want to use from your Cesium Ion account.","title":"Cesium Ion 3D Layers"},{"location":"cesium_ion/#cesium-ion-3d-layers","text":"This guide will take you through the process of opening Cesium Ion 3D layers in a React TypeScript (TSX) application using Resium. Cesium Ion is a cloud-based platform for creating, hosting, and streaming 3D geospatial content, while Resium is a library for integrating Cesium 3D globes with React.","title":"Cesium Ion 3D Layers"},{"location":"cesium_ion/#configuring-cesium-ion","text":"Sign Up for Cesium Ion Before you can use Cesium Ion, you need to create an account on Cesium Ion . Once you have an account, you can obtain your access token. Set Your Access Token Add your Access Token value to the .env file: VITE_CESIUM_TOKEN= In the tsx file, set your Cesium Ion access token by including the following code in your application's entry point (e.g., index.tsx ): import { Ion } from 'cesium' Ion.defaultAccessToken = process.env.VITE_CESIUM_TOKEN","title":"Configuring Cesium Ion"},{"location":"cesium_ion/#opening-a-cesium-ion-3d-layer","text":"Import Required Modules Import the necessary modules: import React from 'react'; import { Viewer } from 'resium'; Define the Cesium Ion Layer Define the Cesium Ion layer within your component: const assetId = 'ASSET ID FROM THE CESIUM ION ACCOUNT' const terrainUrl = await Cesium.CesiumTerrainProvider.fromIonAssetId( assetId, ) ref.current.cesiumElement.terrainProvider = terrainUrl Please note that you will need to replace 'ASSET ID FROM THE CESIUM ION ACCOUNT' with the actual asset ID you want to use from your Cesium Ion account.","title":"Opening a Cesium Ion 3D Layer"},{"location":"cicd/","text":"CI/CD Pipeline Documentation There is an automatic gitlab CI/CD pipeline in this project. It is split into this jobs: Test: pre-commit The Test: pre-commit job is responsible for executing pre-commit tests. Build The Build job is in charge of building the Docker container. The container is tagged based on the container registry name used in the project. Deploy The Deploy job handles the deployment process. It pushes the built container to the BODC container registry. Subsequently, it SSHs into the host named \"web,\" retrieves the container, and restarts it. This process requires the presence of a GitLab Runner user on both the build and web virtual machines. An SSH key must also be configured to allow the build to SSH into the web. Please note that while the salt rules repository can create the user and allow manual key generation for login, it does not generate that key. In the event of VM reinstallation, new SSH keys must be created, and the salt rules (salt/user/gitlab-runner.sls) must be updated with the new keys. Tests: frontend test The Tests: frontend test job focuses on testing your frontend application. It utilizes the code provided in the repository https://github.com/NOC-OI/imfe-pilot-frontend_tests . Ensuring Docker is Logged In To ensure proper functionality, the gitlab-runner user on both the build and web virtual machines must manually log into the Docker registry. This can be achieved using the command docker login docker-repo.bodc.me or docker login uk-london-1.ocir.io . A user dedicated to the CI/CD pipeline is available for this purpose. Firewall Complications Please be aware of potential complications with the NOC firewall, which only allows requests from the fixed IP of the gateway VM. To overcome this restriction, the deploy script sets up an SSH SOCKS proxy on port 3128 via the gateway for pushing and pulling containers. The Docker configuration is adjusted to use localhost:3128 as a proxy, which requires the SSH tunnel to be running. You can initiate the SSH tunnel with the command ssh -D 3128 -f -N gateway before executing any docker login, push, or pull commands. To stop the SSH tunnel, use pkill -f \"ssh -D 3128 -f -N gateway\" .","title":"CI/CD Pipeline Documentation"},{"location":"cicd/#cicd-pipeline-documentation","text":"There is an automatic gitlab CI/CD pipeline in this project. It is split into this jobs:","title":"CI/CD Pipeline Documentation"},{"location":"cicd/#test-pre-commit","text":"The Test: pre-commit job is responsible for executing pre-commit tests.","title":"Test: pre-commit"},{"location":"cicd/#build","text":"The Build job is in charge of building the Docker container. The container is tagged based on the container registry name used in the project.","title":"Build"},{"location":"cicd/#deploy","text":"The Deploy job handles the deployment process. It pushes the built container to the BODC container registry. Subsequently, it SSHs into the host named \"web,\" retrieves the container, and restarts it. This process requires the presence of a GitLab Runner user on both the build and web virtual machines. An SSH key must also be configured to allow the build to SSH into the web. Please note that while the salt rules repository can create the user and allow manual key generation for login, it does not generate that key. In the event of VM reinstallation, new SSH keys must be created, and the salt rules (salt/user/gitlab-runner.sls) must be updated with the new keys.","title":"Deploy"},{"location":"cicd/#tests-frontend-test","text":"The Tests: frontend test job focuses on testing your frontend application. It utilizes the code provided in the repository https://github.com/NOC-OI/imfe-pilot-frontend_tests .","title":"Tests: frontend test"},{"location":"cicd/#ensuring-docker-is-logged-in","text":"To ensure proper functionality, the gitlab-runner user on both the build and web virtual machines must manually log into the Docker registry. This can be achieved using the command docker login docker-repo.bodc.me or docker login uk-london-1.ocir.io . A user dedicated to the CI/CD pipeline is available for this purpose.","title":"Ensuring Docker is Logged In"},{"location":"cicd/#firewall-complications","text":"Please be aware of potential complications with the NOC firewall, which only allows requests from the fixed IP of the gateway VM. To overcome this restriction, the deploy script sets up an SSH SOCKS proxy on port 3128 via the gateway for pushing and pulling containers. The Docker configuration is adjusted to use localhost:3128 as a proxy, which requires the SSH tunnel to be running. You can initiate the SSH tunnel with the command ssh -D 3128 -f -N gateway before executing any docker login, push, or pull commands. To stop the SSH tunnel, use pkill -f \"ssh -D 3128 -f -N gateway\" .","title":"Firewall Complications"},{"location":"cog/","text":"COG (Cloud Optimized GeoTIFF) Introduction In our project, we use Cloud Optimized GeoTIFF (COG) files to efficiently store and display geospatial data. This documentation explains our approach to working with COG files and outlines two distinct methods we've implemented for rendering COG data. Additionally, we emphasize the importance of using a tile server to accelerate frontend map rendering. Utilizing COG Images Cloud Optimized GeoTIFF (COG) files are a specialized format for efficiently storing geospatial data. These files are optimized for performance, allowing rapid access and rendering of large datasets. Tile Server Approach 1) Tile Server powered by www.titiler.xyz One of our methods for accessing COG images involves utilizing a tile server based on www.titiler.xyz . This tile server has been deployed and is currently in production use. You can access the live deployment through the following links: https://imfe-pilot-tileserver.noc.ac.uk.net/ https://haigfras-salt-tileserver.co.uk/ The source code for this tile server can be found in our GitLab repository: tileserver . This repository contains the source code, configuration details, and documentation related to the tile server implementation. 2) Utilizing the georaster Library Another approach for working with COG images involves using the georaster library. This method doesn't require a dedicated tile server. However, it's important to note that, for our project, we have determined that using a tile server significantly improves map rendering speed on the frontend. Both our 2D and 3D maps in the project utilize the tile server option for rendering COG data, ensuring a streamlined and efficient rendering process. Frontend Data Processing In addition to the tile server, we've implemented frontend code to process COG data. This functionality is powered by the Geoblaze library, which enables direct interaction with COG files in the frontend environment. It allows us to perform various operations on COG data directly within the web application. The image above provides an overview of a 2D map displaying a COG image. The chart was generated using the Geoblaze library for data extraction and Plotly for plotting.","title":"COG (Cloud Optimized GeoTIFF)"},{"location":"cog/#cog-cloud-optimized-geotiff","text":"","title":"COG (Cloud Optimized GeoTIFF)"},{"location":"cog/#introduction","text":"In our project, we use Cloud Optimized GeoTIFF (COG) files to efficiently store and display geospatial data. This documentation explains our approach to working with COG files and outlines two distinct methods we've implemented for rendering COG data. Additionally, we emphasize the importance of using a tile server to accelerate frontend map rendering.","title":"Introduction"},{"location":"cog/#utilizing-cog-images","text":"Cloud Optimized GeoTIFF (COG) files are a specialized format for efficiently storing geospatial data. These files are optimized for performance, allowing rapid access and rendering of large datasets.","title":"Utilizing COG Images"},{"location":"cog/#tile-server-approach","text":"","title":"Tile Server Approach"},{"location":"cog/#1-tile-server-powered-by-wwwtitilerxyz","text":"One of our methods for accessing COG images involves utilizing a tile server based on www.titiler.xyz . This tile server has been deployed and is currently in production use. You can access the live deployment through the following links: https://imfe-pilot-tileserver.noc.ac.uk.net/ https://haigfras-salt-tileserver.co.uk/ The source code for this tile server can be found in our GitLab repository: tileserver . This repository contains the source code, configuration details, and documentation related to the tile server implementation.","title":"1) Tile Server powered by www.titiler.xyz"},{"location":"cog/#2-utilizing-the-georaster-library","text":"Another approach for working with COG images involves using the georaster library. This method doesn't require a dedicated tile server. However, it's important to note that, for our project, we have determined that using a tile server significantly improves map rendering speed on the frontend. Both our 2D and 3D maps in the project utilize the tile server option for rendering COG data, ensuring a streamlined and efficient rendering process.","title":"2) Utilizing the georaster Library"},{"location":"cog/#frontend-data-processing","text":"In addition to the tile server, we've implemented frontend code to process COG data. This functionality is powered by the Geoblaze library, which enables direct interaction with COG files in the frontend environment. It allows us to perform various operations on COG data directly within the web application. The image above provides an overview of a 2D map displaying a COG image. The chart was generated using the Geoblaze library for data extraction and Plotly for plotting.","title":"Frontend Data Processing"},{"location":"deploy/","text":"How to Deploy the Digital Twin to a New Server Prerequisites You will need three virtual machines running Ubuntu 22.04, each with 4-8GB of RAM and 10GB of disk space for the OS. Additionally, two of these machines should have an extra 50GB of disk space (can be on an additional disk/volume). The three virtual machines are as follows: - gateway : Runs an Apache transparent proxy server for all services, sets up Let's Encrypt certificates, and provides SSL connections to web apps. - web : Runs the web apps as Docker containers. - build : Functions as a GitLab runner for building and deploying. Only the gateway VM needs an internet-routable IP address. Ensure that you have set the IP address of each system in the Salt pillar hosts file (pillar/hosts.sls) or made sure that the names gateway , web , and build are resolvable via DNS. These virtual machines can be created using the Salt configuration for this project: Salt Configuration Repository . Environment Configuration Files All the following files should exist in the home directory of the gitlab-runner on the web VM. These files are used by various Docker containers at runtime. .tiler-env .env orcid.json tileserver/.env api/.env Setting up the Virtual Machines Create your virtual machines. On JASMIN, this can be done via the Cloud dashboard at JASMIN Cloud Dashboard . Assign an internet IP to the gateway VM. Ensure you can SSH into each VM via the gateway . On the build and web VMs, the Docker directory (/var/lib/docker) needs to have plenty of disk space, approximately 50GB, as Docker doesn't always clean up after itself. You can achieve this by either creating a large main disk or creating a second disk and mounting it in /var/lib/docker. If you choose the latter, ensure it gets mounted from the fstab when the VM reboots. Setting up Hostnames and SSL Certificates The following hostnames are used: - imfe-pilot.noc.ac.uk - imfe-pilot-mbtiles.noc.ac.uk - imfe-pilot-tileserver.noc.ac.uk - imfe-pilot-api.noc.ac.uk Salt is configured to set up Let's Encrypt for these hostnames but might need additional steps to request the initial certificate. Please note that this hasn't been tested since its initial deployment. Setting up Salt Salt is the configuration management system used to set up the operating system on the VMs. Follow the instructions provided in the Salt Configuration Repository . Setting up GitLab Runners You'll need to configure two GitLab runners on the build system: - One should be a Docker runner. - The other should be a shell runner. Give these runners the tags \"docker\" and \"shell.\" The shell runner is used to build Docker containers, while the Docker runner is used to build Python code within a Python Docker container. Ensure that all three GitLab projects (frontend, tileserver, and api_calculations_use_cases) are configured to use these runners. Logging into the Docker Registry Make sure that both the web and build VMs have logged into the Docker container registry from their gitlab-runner user. If you're using the NOC container registry from a non-NOC IP, you'll need IT to allow this through the firewall. Deploying from GitLab Deploy in the following order: tileserver, api_calculations_use_cases, frontend. 1. Go to each project in turn and click on CI/CD, pipelines, run pipeline. 2. If the frontend fails with a message about the frontend not existing, SSH into the web VM and, as the gitlab-runner user, run: docker run -d -p 8080:80 --name frontend docker-repo.bodc.me/oceaninfo/imfe-pilot/frontend:latest , then try again.","title":"How to Deploy the Digital Twin to a New Server"},{"location":"deploy/#how-to-deploy-the-digital-twin-to-a-new-server","text":"","title":"How to Deploy the Digital Twin to a New Server"},{"location":"deploy/#prerequisites","text":"You will need three virtual machines running Ubuntu 22.04, each with 4-8GB of RAM and 10GB of disk space for the OS. Additionally, two of these machines should have an extra 50GB of disk space (can be on an additional disk/volume). The three virtual machines are as follows: - gateway : Runs an Apache transparent proxy server for all services, sets up Let's Encrypt certificates, and provides SSL connections to web apps. - web : Runs the web apps as Docker containers. - build : Functions as a GitLab runner for building and deploying. Only the gateway VM needs an internet-routable IP address. Ensure that you have set the IP address of each system in the Salt pillar hosts file (pillar/hosts.sls) or made sure that the names gateway , web , and build are resolvable via DNS. These virtual machines can be created using the Salt configuration for this project: Salt Configuration Repository .","title":"Prerequisites"},{"location":"deploy/#environment-configuration-files","text":"All the following files should exist in the home directory of the gitlab-runner on the web VM. These files are used by various Docker containers at runtime.","title":"Environment Configuration Files"},{"location":"deploy/#tiler-env","text":"","title":".tiler-env"},{"location":"deploy/#env","text":"","title":".env"},{"location":"deploy/#orcidjson","text":"","title":"orcid.json"},{"location":"deploy/#tileserverenv","text":"","title":"tileserver/.env"},{"location":"deploy/#apienv","text":"","title":"api/.env"},{"location":"deploy/#setting-up-the-virtual-machines","text":"Create your virtual machines. On JASMIN, this can be done via the Cloud dashboard at JASMIN Cloud Dashboard . Assign an internet IP to the gateway VM. Ensure you can SSH into each VM via the gateway . On the build and web VMs, the Docker directory (/var/lib/docker) needs to have plenty of disk space, approximately 50GB, as Docker doesn't always clean up after itself. You can achieve this by either creating a large main disk or creating a second disk and mounting it in /var/lib/docker. If you choose the latter, ensure it gets mounted from the fstab when the VM reboots.","title":"Setting up the Virtual Machines"},{"location":"deploy/#setting-up-hostnames-and-ssl-certificates","text":"The following hostnames are used: - imfe-pilot.noc.ac.uk - imfe-pilot-mbtiles.noc.ac.uk - imfe-pilot-tileserver.noc.ac.uk - imfe-pilot-api.noc.ac.uk Salt is configured to set up Let's Encrypt for these hostnames but might need additional steps to request the initial certificate. Please note that this hasn't been tested since its initial deployment.","title":"Setting up Hostnames and SSL Certificates"},{"location":"deploy/#setting-up-salt","text":"Salt is the configuration management system used to set up the operating system on the VMs. Follow the instructions provided in the Salt Configuration Repository .","title":"Setting up Salt"},{"location":"deploy/#setting-up-gitlab-runners","text":"You'll need to configure two GitLab runners on the build system: - One should be a Docker runner. - The other should be a shell runner. Give these runners the tags \"docker\" and \"shell.\" The shell runner is used to build Docker containers, while the Docker runner is used to build Python code within a Python Docker container. Ensure that all three GitLab projects (frontend, tileserver, and api_calculations_use_cases) are configured to use these runners.","title":"Setting up GitLab Runners"},{"location":"deploy/#logging-into-the-docker-registry","text":"Make sure that both the web and build VMs have logged into the Docker container registry from their gitlab-runner user. If you're using the NOC container registry from a non-NOC IP, you'll need IT to allow this through the firewall.","title":"Logging into the Docker Registry"},{"location":"deploy/#deploying-from-gitlab","text":"Deploy in the following order: tileserver, api_calculations_use_cases, frontend. 1. Go to each project in turn and click on CI/CD, pipelines, run pipeline. 2. If the frontend fails with a message about the frontend not existing, SSH into the web VM and, as the gitlab-runner user, run: docker run -d -p 8080:80 --name frontend docker-repo.bodc.me/oceaninfo/imfe-pilot/frontend:latest , then try again.","title":"Deploying from GitLab"},{"location":"frontend/","text":"Frontend Documentation It was created a frontend application developed in React, with the ability to interact with different data formats on both the backend and frontend. The project relies on specific backend services for tile server operations, authentication, and data calculations. For more information, please refer to the project repository . Access The frontend application is currently hosted on Jasmin and Oracle Cloud, and you can access it through the following links: https://imfe-pilot.noc.ac.uk/ https://haigfras-salt.co.uk/ General Project Infrastructure The frontend accesses data from various sources and utilizes different microservices. All these services are containerized using Docker for easy deployment and management. Website Organization The structure of the web application is primarily centered around the configuration file /public/website.json . This file defines the general structure of the items in the site's sidebar. It's important to exercise caution when making changes to this file, as it can potentially affect the organization of the site. Within this configuration file, you can add the following elements: - New sections to the sidebar - Information for info buttons - Change backend endpoints You can change the location of the website.json file by modifying the environment variable 'VITE_WEBSITE_JSON_URL'. Layers Organization The organization of the layers rendered in the application is managed through the STAC Catalog of the project. Using the Data Pipelines package, the STAC is converted into a JSON file that the frontend can interpret and encode. Currently, in the project, these JSON files are stored in the Object Store. You should set the correct path for these files in the following environment variables: VITE_LAYERS_JSON_URL and VITE_LAYERS3D_JSON_URL. Features Authentication For access control to the site, two types of authentication have been implemented: ORCID and Microsoft 365. You can find more details in the Authentication documentation . 2D Map The 2D version is based on the React Leaflet library. For comprehensive information on the 2D map, please refer to the 2D Map documentation . 3D Map The 3D version is built using the Resium library, which is Cesium for React. Find more details about the 3D map in the 3D Map documentation . Map Layers The layers used in the maps are generated from the STAC Catalog of the project. To do this, you need to convert the STAC Catalog into a JSON file and save it in the appropriate location. More information about this conversion is available at the repository data-pipelines . It's essential to set this location as environment variables, VITE_LAYERS_JSON_URL and VITE_LAYERS3D_JSON_URL . Interaction with Different Data Types Various techniques are applied to process and render maps for various data formats, including: - Cloud Optimized GeoTIFF - MBTiles - WMS Layers - Cesium Ion - Photos Frontend Calculations The frontend utilizes the GeoBlaze library for performing specific operations. This library is particularly useful for conducting simple statistical operations on GeoTIFF files. When working with COG format images, it's important to download only the necessary tiles and then perform mathematical operations. Backend Calculations While most activities can be handled on the frontend, a backend has been implemented for specific calculations. You can find more information about these calculations in the Backend Calculations documentation .","title":"Frontend Documentation"},{"location":"frontend/#frontend-documentation","text":"It was created a frontend application developed in React, with the ability to interact with different data formats on both the backend and frontend. The project relies on specific backend services for tile server operations, authentication, and data calculations. For more information, please refer to the project repository .","title":"Frontend Documentation"},{"location":"frontend/#access","text":"The frontend application is currently hosted on Jasmin and Oracle Cloud, and you can access it through the following links: https://imfe-pilot.noc.ac.uk/ https://haigfras-salt.co.uk/","title":"Access"},{"location":"frontend/#general-project-infrastructure","text":"The frontend accesses data from various sources and utilizes different microservices. All these services are containerized using Docker for easy deployment and management.","title":"General Project Infrastructure"},{"location":"frontend/#website-organization","text":"The structure of the web application is primarily centered around the configuration file /public/website.json . This file defines the general structure of the items in the site's sidebar. It's important to exercise caution when making changes to this file, as it can potentially affect the organization of the site. Within this configuration file, you can add the following elements: - New sections to the sidebar - Information for info buttons - Change backend endpoints You can change the location of the website.json file by modifying the environment variable 'VITE_WEBSITE_JSON_URL'.","title":"Website Organization"},{"location":"frontend/#layers-organization","text":"The organization of the layers rendered in the application is managed through the STAC Catalog of the project. Using the Data Pipelines package, the STAC is converted into a JSON file that the frontend can interpret and encode. Currently, in the project, these JSON files are stored in the Object Store. You should set the correct path for these files in the following environment variables: VITE_LAYERS_JSON_URL and VITE_LAYERS3D_JSON_URL.","title":"Layers Organization"},{"location":"frontend/#features","text":"","title":"Features"},{"location":"frontend/#authentication","text":"For access control to the site, two types of authentication have been implemented: ORCID and Microsoft 365. You can find more details in the Authentication documentation .","title":"Authentication"},{"location":"frontend/#2d-map","text":"The 2D version is based on the React Leaflet library. For comprehensive information on the 2D map, please refer to the 2D Map documentation .","title":"2D Map"},{"location":"frontend/#3d-map","text":"The 3D version is built using the Resium library, which is Cesium for React. Find more details about the 3D map in the 3D Map documentation .","title":"3D Map"},{"location":"frontend/#map-layers","text":"The layers used in the maps are generated from the STAC Catalog of the project. To do this, you need to convert the STAC Catalog into a JSON file and save it in the appropriate location. More information about this conversion is available at the repository data-pipelines . It's essential to set this location as environment variables, VITE_LAYERS_JSON_URL and VITE_LAYERS3D_JSON_URL .","title":"Map Layers"},{"location":"frontend/#interaction-with-different-data-types","text":"Various techniques are applied to process and render maps for various data formats, including: - Cloud Optimized GeoTIFF - MBTiles - WMS Layers - Cesium Ion - Photos","title":"Interaction with Different Data Types"},{"location":"frontend/#frontend-calculations","text":"The frontend utilizes the GeoBlaze library for performing specific operations. This library is particularly useful for conducting simple statistical operations on GeoTIFF files. When working with COG format images, it's important to download only the necessary tiles and then perform mathematical operations.","title":"Frontend Calculations"},{"location":"frontend/#backend-calculations","text":"While most activities can be handled on the frontend, a backend has been implemented for specific calculations. You can find more information about these calculations in the Backend Calculations documentation .","title":"Backend Calculations"},{"location":"mbtiles/","text":"MBTiles Introduction MBTiles are files used to store vector data in the form of an SQLite database. In our project, we utilize MBTiles as a critical component for efficiently managing and rendering vector data. This documentation explains how MBTiles are used in our system and provides insights into the processes and infrastructure that support them. MBTiles File Format MBTiles serve as the fundamental data format for storing vector information. They are employed to manage spatial data in a compact and organized manner. These files essentially consist of SQLite databases optimized for spatial queries. Server for Handling MBTiles To access and process MBTiles files, we've developed a Python-based service. This service is responsible for executing queries on the database and returning the specific data required for rendering on the frontend. It plays a pivotal role in ensuring that only relevant map data is retrieved and displayed on the map, optimizing both performance and resource utilization. Our MBTiles server is based on the mbtiles-s3-server library, which provides efficient and scalable methods for serving MBTiles data. This service is currently in production and can be accessed through the following links: https://imfe-pilot-mbtiles.noc.ac.uk.net/ https://haigfras-salt-mbtiles.co.uk/ Project Repository The codebase for our MBTiles service is hosted on GitLab, and you can access the repository at https://github.com/NOC-OI/imfe-pilot-tileserver . This repository contains the source code, documentation, and configurations related to our MBTiles server. Generating MBTiles Data For this project, we are using the output of the EUSeaMap 2021 large-scale predictive model produced by EMODnet Seabed Habitats. The data was extracted from here in Geodatabase format. It was converted to GeoJSON format using the GDAL library . Finally, the GeoJSON file was converted to MBTiles format, representing an SQLite database, using the tippecanoe library . The conversion utilized the \"\u2014drop-densest-as-needed\" option. Detailed steps for file conversion are described in the repository . Map Visualization To provide a visual overview, here's an example of a 2D map rendering using MBTiles data: The above image illustrates a 2D map visualization using MBTiles data. Limitations in 3D Mapping It's important to note that due to certain limitations imposed by the Cesium library, opening MBTiles files in 3D maps is not currently supported. Our project primarily focuses on optimizing 2D map rendering, and we are actively exploring solutions to extend this functionality to 3D mapping in the future.","title":"MBTiles"},{"location":"mbtiles/#mbtiles","text":"","title":"MBTiles"},{"location":"mbtiles/#introduction","text":"MBTiles are files used to store vector data in the form of an SQLite database. In our project, we utilize MBTiles as a critical component for efficiently managing and rendering vector data. This documentation explains how MBTiles are used in our system and provides insights into the processes and infrastructure that support them.","title":"Introduction"},{"location":"mbtiles/#mbtiles-file-format","text":"MBTiles serve as the fundamental data format for storing vector information. They are employed to manage spatial data in a compact and organized manner. These files essentially consist of SQLite databases optimized for spatial queries.","title":"MBTiles File Format"},{"location":"mbtiles/#server-for-handling-mbtiles","text":"To access and process MBTiles files, we've developed a Python-based service. This service is responsible for executing queries on the database and returning the specific data required for rendering on the frontend. It plays a pivotal role in ensuring that only relevant map data is retrieved and displayed on the map, optimizing both performance and resource utilization. Our MBTiles server is based on the mbtiles-s3-server library, which provides efficient and scalable methods for serving MBTiles data. This service is currently in production and can be accessed through the following links: https://imfe-pilot-mbtiles.noc.ac.uk.net/ https://haigfras-salt-mbtiles.co.uk/","title":"Server for Handling MBTiles"},{"location":"mbtiles/#project-repository","text":"The codebase for our MBTiles service is hosted on GitLab, and you can access the repository at https://github.com/NOC-OI/imfe-pilot-tileserver . This repository contains the source code, documentation, and configurations related to our MBTiles server.","title":"Project Repository"},{"location":"mbtiles/#generating-mbtiles-data","text":"For this project, we are using the output of the EUSeaMap 2021 large-scale predictive model produced by EMODnet Seabed Habitats. The data was extracted from here in Geodatabase format. It was converted to GeoJSON format using the GDAL library . Finally, the GeoJSON file was converted to MBTiles format, representing an SQLite database, using the tippecanoe library . The conversion utilized the \"\u2014drop-densest-as-needed\" option. Detailed steps for file conversion are described in the repository .","title":"Generating MBTiles Data"},{"location":"mbtiles/#map-visualization","text":"To provide a visual overview, here's an example of a 2D map rendering using MBTiles data: The above image illustrates a 2D map visualization using MBTiles data.","title":"Map Visualization"},{"location":"mbtiles/#limitations-in-3d-mapping","text":"It's important to note that due to certain limitations imposed by the Cesium library, opening MBTiles files in 3D maps is not currently supported. Our project primarily focuses on optimizing 2D map rendering, and we are actively exploring solutions to extend this functionality to 3D mapping in the future.","title":"Limitations in 3D Mapping"},{"location":"object_store/","text":"OBJECT STORE ORGANIZATION This document provides a description of the organization of the Pilot-imfe Tenancy on the Jasmin Object Store. The goal is to facilitate future applications of the same infrastructure in new digital twin or GIS systems projects. REQUIREMENTS For the assembly of an infrastructure for digital twin projects, some system requirements are necessary: - The bucket must have open access. A significant portion of the data will be made available to the public through the publication of the data's DOI. Therefore, it is important that the public can download most of the data without login issues or the need for registration. The bucket must have access control for some types of files. Depending on the data, the client may request that it has restricted access. The bucket must support versioning. Depending on the data format on the frontend, some libraries require that the bucket has version control. File Types The bucket must contain all CSV files, COG images, GeoTIFFs, PNGs, JPGs, as well as MBTILES, GEOJSON, SHP, and GEOPARQUET files. The bucket must include the structure and JSON of the STAC catalog. The bucket should contain all JSON files related to the catalogs and data of the STAC catalog. The bucket must contain the files used to populate the frontend. If the frontend requires images or JSON files to populate the site, they should be stored in the bucket. BUCKETS In order to meet all the requirements described above and at the same time align with the space and scalability needs of the project, the following bucket configuration was chosen: 1 bucket to store open access data without versioning control. 1 bucket to store data with access control. 1 bucket with versioning control. The three buckets will have the same data organization, which will facilitate interoperability between them. In other words, if a file needs to be accessed in the access-controlled bucket, the data path will be the same as if the file were in the open bucket. FILE SYSTEM The buckets have the following folder organization: \u251c\u2500\u2500 frontend \u2502 \u251c\u2500\u2500 images \u2502 \u2502 \u251c\u2500\u2500 image1.png \u2502 \u251c\u2500\u2500 layers.json \u2502 \u251c\u2500\u2500 layers3d.json \u2502 \u251c\u2500\u2500 website.json \u251c\u2500\u2500 STAC_Catalogue \u2502 \u251c\u2500\u2500 layer_type1 \u2502 \u2502 \u251c\u2500\u2500 layer1 \u2502 \u2502 \u2502 \u251c\u2500\u2500 layer1.json \u2502 \u2502 \u251c\u2500\u2500 colection.json \u2502 \u251c\u2500\u2500 layer_type2 \u2502 \u251c\u2500\u2500 catalog.json \u251c\u2500\u2500 layers \u2502 \u251c\u2500\u2500 layer_type1 \u2502 \u2502 \u251c\u2500\u2500 layer1 \u2502 \u2502 \u2502 \u251c\u2500\u2500 aditional directiories \u2502 \u2502 \u2502 \u251c\u2500\u2500 layer1.csv or .tif or .mbtiles or ... \u2502 \u2502 \u251c\u2500\u2500 layer2 \u2502 \u251c\u2500\u2500 layer_type2 \u2502 \u2502 \u251c\u2500\u2500 layer1 \u2502 \u2502 \u251c\u2500\u2500 layer2 \u2514\u2500\u2500","title":"OBJECT STORE ORGANIZATION"},{"location":"object_store/#object-store-organization","text":"This document provides a description of the organization of the Pilot-imfe Tenancy on the Jasmin Object Store. The goal is to facilitate future applications of the same infrastructure in new digital twin or GIS systems projects.","title":"OBJECT STORE ORGANIZATION"},{"location":"object_store/#requirements","text":"For the assembly of an infrastructure for digital twin projects, some system requirements are necessary: - The bucket must have open access. A significant portion of the data will be made available to the public through the publication of the data's DOI. Therefore, it is important that the public can download most of the data without login issues or the need for registration. The bucket must have access control for some types of files. Depending on the data, the client may request that it has restricted access. The bucket must support versioning. Depending on the data format on the frontend, some libraries require that the bucket has version control. File Types The bucket must contain all CSV files, COG images, GeoTIFFs, PNGs, JPGs, as well as MBTILES, GEOJSON, SHP, and GEOPARQUET files. The bucket must include the structure and JSON of the STAC catalog. The bucket should contain all JSON files related to the catalogs and data of the STAC catalog. The bucket must contain the files used to populate the frontend. If the frontend requires images or JSON files to populate the site, they should be stored in the bucket.","title":"REQUIREMENTS"},{"location":"object_store/#buckets","text":"In order to meet all the requirements described above and at the same time align with the space and scalability needs of the project, the following bucket configuration was chosen: 1 bucket to store open access data without versioning control. 1 bucket to store data with access control. 1 bucket with versioning control. The three buckets will have the same data organization, which will facilitate interoperability between them. In other words, if a file needs to be accessed in the access-controlled bucket, the data path will be the same as if the file were in the open bucket.","title":"BUCKETS"},{"location":"object_store/#file-system","text":"The buckets have the following folder organization: \u251c\u2500\u2500 frontend \u2502 \u251c\u2500\u2500 images \u2502 \u2502 \u251c\u2500\u2500 image1.png \u2502 \u251c\u2500\u2500 layers.json \u2502 \u251c\u2500\u2500 layers3d.json \u2502 \u251c\u2500\u2500 website.json \u251c\u2500\u2500 STAC_Catalogue \u2502 \u251c\u2500\u2500 layer_type1 \u2502 \u2502 \u251c\u2500\u2500 layer1 \u2502 \u2502 \u2502 \u251c\u2500\u2500 layer1.json \u2502 \u2502 \u251c\u2500\u2500 colection.json \u2502 \u251c\u2500\u2500 layer_type2 \u2502 \u251c\u2500\u2500 catalog.json \u251c\u2500\u2500 layers \u2502 \u251c\u2500\u2500 layer_type1 \u2502 \u2502 \u251c\u2500\u2500 layer1 \u2502 \u2502 \u2502 \u251c\u2500\u2500 aditional directiories \u2502 \u2502 \u2502 \u251c\u2500\u2500 layer1.csv or .tif or .mbtiles or ... \u2502 \u2502 \u251c\u2500\u2500 layer2 \u2502 \u251c\u2500\u2500 layer_type2 \u2502 \u2502 \u251c\u2500\u2500 layer1 \u2502 \u2502 \u251c\u2500\u2500 layer2 \u2514\u2500\u2500","title":"FILE SYSTEM"},{"location":"photos/","text":"CSV - Organisms Annotations In this project, we are working directly with data related to underwater photographs and annotations of marine organism occurrences. There is no standard for organizing this type of data and presenting it on a website. Currently, in this project, we are working with the following data sources: NOC Haig Fras 2012 autonomous underwater vehicle image survey NOC Haig Fras 2015 autonomous underwater vehicle image survey JNCC CEND2012 Survey National Biodiversity Network (NBN) Gateway The files were obtained from different sources in different formats. The following steps and data organization strategies will be described: Initial Format Regarding the two NOC campaigns, the purpose was to capture seafloor images. These images underwent internal processing and organization and were converted to JPG files. In some cases, the images were also converted and georeferenced to GeoTIFF format. Along with the images, a CSV file with annotations related to organism observations and counts was also provided. For the JNCC campaign, images in JPG format and a list with the positions and occurrences of organisms were provided. For the NBN Atlas, data were extracted from https://nbnatlas.org . The NBN Atlas data were filtered by drawing a bounding box in the region of the Greater Haig Fras Marine Protected Area (MPA). Datasets without the CC-BY or CC-BY-NC license were removed. Datasets related to bird and planktonic surveys were individually excluded from the search. Format Conversion All CSV files were converted to GeoJSON and saved in the Object Store to facilitate plotting and data work on the frontend. For GeoTIFF images, they were converted to the COG format, also with the goal of accelerating rendering on the frontend. It should be noted that for NBN data, this download was subsequently passed through the World Register of Marine Species (WoRMS) Taxon Matching tool , and the output was manually filtered to further restrict the output to contain only plants and invertebrate animals, excluding plankton. It should be noted that the CSV files, GeoJSON, JPG, and COG images were described in the STAC Catalog of these images . Presentation on the Frontend For presenting the data on maps, the frontend fetches the GeoJSON files, which contain all the necessary information for plotting on the maps. Example of how photos are arranged and presented in the frontend application Example of one of the underwater images","title":"CSV - Organisms Annotations"},{"location":"photos/#csv-organisms-annotations","text":"In this project, we are working directly with data related to underwater photographs and annotations of marine organism occurrences. There is no standard for organizing this type of data and presenting it on a website. Currently, in this project, we are working with the following data sources: NOC Haig Fras 2012 autonomous underwater vehicle image survey NOC Haig Fras 2015 autonomous underwater vehicle image survey JNCC CEND2012 Survey National Biodiversity Network (NBN) Gateway The files were obtained from different sources in different formats. The following steps and data organization strategies will be described:","title":"CSV - Organisms Annotations"},{"location":"photos/#initial-format","text":"Regarding the two NOC campaigns, the purpose was to capture seafloor images. These images underwent internal processing and organization and were converted to JPG files. In some cases, the images were also converted and georeferenced to GeoTIFF format. Along with the images, a CSV file with annotations related to organism observations and counts was also provided. For the JNCC campaign, images in JPG format and a list with the positions and occurrences of organisms were provided. For the NBN Atlas, data were extracted from https://nbnatlas.org . The NBN Atlas data were filtered by drawing a bounding box in the region of the Greater Haig Fras Marine Protected Area (MPA). Datasets without the CC-BY or CC-BY-NC license were removed. Datasets related to bird and planktonic surveys were individually excluded from the search.","title":"Initial Format"},{"location":"photos/#format-conversion","text":"All CSV files were converted to GeoJSON and saved in the Object Store to facilitate plotting and data work on the frontend. For GeoTIFF images, they were converted to the COG format, also with the goal of accelerating rendering on the frontend. It should be noted that for NBN data, this download was subsequently passed through the World Register of Marine Species (WoRMS) Taxon Matching tool , and the output was manually filtered to further restrict the output to contain only plants and invertebrate animals, excluding plankton. It should be noted that the CSV files, GeoJSON, JPG, and COG images were described in the STAC Catalog of these images .","title":"Format Conversion"},{"location":"photos/#presentation-on-the-frontend","text":"For presenting the data on maps, the frontend fetches the GeoJSON files, which contain all the necessary information for plotting on the maps. Example of how photos are arranged and presented in the frontend application Example of one of the underwater images","title":"Presentation on the Frontend"},{"location":"stac/","text":"STAC Catalog In order to manage a group of files within the object store, it is essential to create a catalog known as a STAC Catalog . The STAC specification provides a common language for describing geospatial information, making it easier to work with, index, and discover such data. You can access the STAC catalog for this project at this link . For detailed information on generating a STAC Catalog, please refer to the Data Pipelines repository . Creating STAC Catalogs To create STAC Catalogs for this project, you'll need to utilize the Data Pipelines Package . Follow these steps: Create a set of configuration files referred to as \"metadata.\" Metadata files include a primary JSON file representing the main catalog. Depending on the data group, if you wish to add sub-catalogs to your catalog, you can create auxiliary JSON files. The repository provides a list of example files. Import the function and create an instance of the class in Python: from create_stac.stac_gen import STACGen # Create an instance of the class and provide the path to your metadata files (JSON files) s = STACGen(metadata_path='../metadatas/') Generate the STAC Catalog: s.stac_gen(upload_bucket=True, stac_path='stac' ) Upon completion, a folder named \"stac\" will be created containing your STAC Catalog. Generating JSON for Web Applications When using STAC Catalogs in a frontend, importing all the individual files can be time-consuming. To expedite this process, a set of scripts has been created to convert the STAC into a single user-friendly JSON format that can be accepted by web applications. Currently, we are converting the STAC into a JSON format suitable for the \"Haig Fras Digital Twin\" project. To generate the JSON file, follow these steps: Import the function and create an instance of the class in Python: from create_stac.stac_convert import STACConvert c = STACConvert(bucket_path='', stac_path='stac') Generate the JSON file from the STAC Catalog: c.convert() Save the final JSON file and upload it to the object store: c.save_and upload(filename='layers.json') At this point, a file named \"layers.json\" will be created and ready for use by the web application. Set the following environment variables in your frontend project with information related to the path of your JSON file: \"VITE_LAYERS_JSON_URL\" and \"VITE_LAYERS3D_JSON_URL\".","title":"STAC Catalog"},{"location":"stac/#stac-catalog","text":"In order to manage a group of files within the object store, it is essential to create a catalog known as a STAC Catalog . The STAC specification provides a common language for describing geospatial information, making it easier to work with, index, and discover such data. You can access the STAC catalog for this project at this link . For detailed information on generating a STAC Catalog, please refer to the Data Pipelines repository .","title":"STAC Catalog"},{"location":"stac/#creating-stac-catalogs","text":"To create STAC Catalogs for this project, you'll need to utilize the Data Pipelines Package . Follow these steps: Create a set of configuration files referred to as \"metadata.\" Metadata files include a primary JSON file representing the main catalog. Depending on the data group, if you wish to add sub-catalogs to your catalog, you can create auxiliary JSON files. The repository provides a list of example files. Import the function and create an instance of the class in Python: from create_stac.stac_gen import STACGen # Create an instance of the class and provide the path to your metadata files (JSON files) s = STACGen(metadata_path='../metadatas/') Generate the STAC Catalog: s.stac_gen(upload_bucket=True, stac_path='stac' ) Upon completion, a folder named \"stac\" will be created containing your STAC Catalog.","title":"Creating STAC Catalogs"},{"location":"stac/#generating-json-for-web-applications","text":"When using STAC Catalogs in a frontend, importing all the individual files can be time-consuming. To expedite this process, a set of scripts has been created to convert the STAC into a single user-friendly JSON format that can be accepted by web applications. Currently, we are converting the STAC into a JSON format suitable for the \"Haig Fras Digital Twin\" project. To generate the JSON file, follow these steps: Import the function and create an instance of the class in Python: from create_stac.stac_convert import STACConvert c = STACConvert(bucket_path='', stac_path='stac') Generate the JSON file from the STAC Catalog: c.convert() Save the final JSON file and upload it to the object store: c.save_and upload(filename='layers.json') At this point, a file named \"layers.json\" will be created and ready for use by the web application. Set the following environment variables in your frontend project with information related to the path of your JSON file: \"VITE_LAYERS_JSON_URL\" and \"VITE_LAYERS3D_JSON_URL\".","title":"Generating JSON for Web Applications"},{"location":"wms/","text":"WMS Layers This guide will walk you through the process of loading Web Map Service (WMS) layers in a React application using React-Leaflet for 2D maps and Resium for 3D maps. WMS is a standard protocol for serving georeferenced map images over the internet. Web Mapping Services from the following institutions are being accessed to add layers to the map: - JNCC: https://jncc.gov.uk/our-work/marine-protected-area-mapper/ - EMODNET: https://emodnet.ec.europa.eu/en/emodnet-web-service-documentation Loading WMS Layers with React-Leaflet Import Required Modules Import the necessary modules in your WMSLayer.js file: tsx import React from 'react'; import { MapContainer, TileLayer, WMSTileLayer } from 'react-leaflet'; Define the WMS Layer Define the WMS layer within your component, specifying the URL, layers, and other options: ```tsx export function WMSLayer(){ return ( ); }; Use the Component Import and use your WMSLayer component in your main application file: ```tsx import React from 'react'; import { WMSLayer } from './WMSLayer'; export function App() { return ( ); } export default App; ``` Loading WMS Layers with Resium (3D Maps) Import Required Modules tsx import React from 'react'; import { Viewer, ImageryLayer } from 'resium'; import Cesium from 'cesium'; Define the WMS Layer Define the WMS layer within your component: tsx export function WMSLayer(){ return ( <Viewer full> <ImageryLayer imageryProvider={new Cesium.WebMapServiceImageryProvider({ url: 'URL_TO_YOUR_WMS_SERVICE', layers: 'LAYER_NAME', })} /> </Viewer> ); };","title":"WMS Layers"},{"location":"wms/#wms-layers","text":"This guide will walk you through the process of loading Web Map Service (WMS) layers in a React application using React-Leaflet for 2D maps and Resium for 3D maps. WMS is a standard protocol for serving georeferenced map images over the internet. Web Mapping Services from the following institutions are being accessed to add layers to the map: - JNCC: https://jncc.gov.uk/our-work/marine-protected-area-mapper/ - EMODNET: https://emodnet.ec.europa.eu/en/emodnet-web-service-documentation","title":"WMS Layers"},{"location":"wms/#loading-wms-layers-with-react-leaflet","text":"Import Required Modules Import the necessary modules in your WMSLayer.js file: tsx import React from 'react'; import { MapContainer, TileLayer, WMSTileLayer } from 'react-leaflet'; Define the WMS Layer Define the WMS layer within your component, specifying the URL, layers, and other options: ```tsx export function WMSLayer(){ return ( ); }; Use the Component Import and use your WMSLayer component in your main application file: ```tsx import React from 'react'; import { WMSLayer } from './WMSLayer'; export function App() { return ( ); } export default App; ```","title":"Loading WMS Layers with React-Leaflet"},{"location":"wms/#loading-wms-layers-with-resium-3d-maps","text":"Import Required Modules tsx import React from 'react'; import { Viewer, ImageryLayer } from 'resium'; import Cesium from 'cesium'; Define the WMS Layer Define the WMS layer within your component: tsx export function WMSLayer(){ return ( <Viewer full> <ImageryLayer imageryProvider={new Cesium.WebMapServiceImageryProvider({ url: 'URL_TO_YOUR_WMS_SERVICE', layers: 'LAYER_NAME', })} /> </Viewer> ); };","title":"Loading WMS Layers with Resium (3D Maps)"}]}